{"cells":[{"cell_type":"markdown","metadata":{"id":"91TL35b2lTHj"},"source":["# Instalación de Hadoop HDFS"]},{"cell_type":"markdown","metadata":{"id":"-6hkmh73pfkr"},"source":["Este código está destinado a configurar un entorno Hadoop en Google Colab utilizando Python y comandos de shell. Hadoop es un framework de código abierto diseñado para procesar y almacenar grandes conjuntos de datos en clústeres de hardware. El código que has proporcionado realiza una serie de pasos para instalar, configurar y ejecutar un entorno Hadoop básico en Colab.\n","\n","1. **Instalar Java:**\n","   ```\n","   !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","   ```\n","   Este comando utiliza el comando `apt-get` para instalar la versión 8 de OpenJDK (Java Development Kit) sin mostrar mensajes en la salida estándar.\n","\n","2. **Descargar Hadoop:**\n","   ```\n","   !wget https://downloads.apache.org/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz\n","   !tar -xvf hadoop-3.3.1.tar.gz\n","   ```\n","   Aquí, se descarga el archivo tar.gz de Hadoop 3.3.1 desde el servidor de descargas de Apache y luego se descomprime usando `tar`.\n","\n","3. **Configurar variables de entorno para Colab:**\n","   ```python\n","   import os\n","   os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","   os.environ[\"HADOOP_HOME\"] = \"/content/hadoop-3.3.1\"\n","   ```\n","   Se configuran las variables de entorno `JAVA_HOME` y `HADOOP_HOME` para que los comandos futuros puedan encontrar la ubicación de Java y Hadoop en el sistema.\n","\n","4. **Crear un usuario falso para Hadoop:**\n","   ```\n","   !addgroup hadoop\n","   !adduser --disabled-password --gecos '' hduser\n","   !adduser hduser hadoop\n","   ```\n","   Aquí se crea un grupo llamado \"hadoop\" y un usuario llamado \"hduser\" dentro del grupo. Este usuario se utiliza para ejecutar procesos de Hadoop.\n","\n","5. **Establecer variables de entorno HDFS para el usuario hduser:**\n","   ```python\n","   os.environ[\"HDFS_NAMENODE_USER\"] = \"hduser\"\n","   os.environ[\"HDFS_DATANODE_USER\"] = \"hduser\"\n","   os.environ[\"HDFS_SECONDARYNAMENODE_USER\"] = \"hduser\"\n","   ```\n","   Se configuran variables de entorno relacionadas con los usuarios para los diferentes componentes de Hadoop.\n","\n","6. **Configurar archivos XML de Hadoop:**\n","   Aquí se generan y configuran los archivos de configuración de Hadoop, `core-site.xml` y `hdfs-site.xml`. Estos archivos determinan la configuración del sistema de archivos distribuido HDFS.\n","   \n","7. **Cambiar propiedad y permisos del directorio Hadoop:**\n","   ```\n","   !chown -R hduser:hadoop /content/hadoop-3.3.1\n","   !chmod -R 755 /content/hadoop-3.3.1\n","   ```\n","   Se cambian los propietarios y permisos de los archivos y directorios de Hadoop para que el usuario \"hduser\" tenga acceso.\n","\n","8. **Crear el directorio de registros:**\n","   ```\n","   !mkdir -p /content/hadoop-3.3.1/logs\n","   !chown -R hduser:hadoop /content/hadoop-3.3.1/logs\n","   ```\n","   Se crea un directorio para los registros de Hadoop y se ajustan los permisos.\n","\n","9. **Formatear el sistema de archivos HDFS:**\n","   ```\n","   !su - hduser -c \"export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 && /content/hadoop-3.3.1/bin/hdfs namenode -format\"\n","   ```\n","   Se formatea el sistema de archivos HDFS, lo que borra todos los datos existentes y prepara el sistema para su uso.\n","\n","10. **Iniciar el NameNode y DataNode manualmente:**\n","    Aquí, los componentes NameNode y DataNode de Hadoop se inician en segundo plano.\n","\n","11. **Crear un directorio en HDFS y listar directorios:**\n","    Se crea un directorio llamado \"demo\" en el sistema de archivos distribuido HDFS y luego se lista el contenido del directorio raíz.\n","\n","12. **Listar procesos Java en ejecución:**\n","    ```\n","    !su - hduser -c \"jps\"\n","    ```\n","    El comando `jps` muestra los procesos Java en ejecución, lo que permite verificar que los componentes de Hadoop estén funcionando.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50951,"status":"ok","timestamp":1743886474730,"user":{"displayName":"RICARDO ALONZO FERNANDEZ SALGUERO","userId":"12473278373138358385"},"user_tz":-120},"id":"77ZM_RiatsBY","outputId":"e8324c16-0da7-4da2-93d6-1484a6f9ed7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["addgroup: The group `hadoop' already exists.\n","adduser: The user `hduser' already exists.\n","The user `hduser' is already a member of `hadoop'.\n","namenode is running as process 1674.  Stop it first and ensure /tmp/hadoop-hduser-namenode.pid file is empty before retry.\n","Starting namenodes on [localhost]\n","localhost: ssh: connect to host localhost port 22: Cannot assign requested address\n","Starting datanodes\n","localhost: ssh: connect to host localhost port 22: Cannot assign requested address\n","Starting secondary namenodes [17d23a5398da]\n","17d23a5398da: ssh: connect to host 17d23a5398da port 22: Connection refused\n"]}],"source":["# Instalar Java\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","\n","# Descargar Hadoop\n","!wget -q https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz\n","!tar -xvf hadoop-3.3.6.tar.gz > /dev/null\n","\n","# Configurar las variables de entorno para Hadoop\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"HADOOP_HOME\"] = \"/content/hadoop-3.3.6\"\n","os.environ[\"PATH\"] += os.pathsep + os.path.join(os.environ[\"HADOOP_HOME\"], \"bin\")\n","\n","# Crear un usuario ficticio para Hadoop\n","!addgroup hadoop\n","!adduser --disabled-password --gecos '' hduser\n","!adduser hduser hadoop\n","\n","# Establecer variables de entorno HDFS para el usuario hduser\n","os.environ[\"HDFS_NAMENODE_USER\"] = \"hduser\"\n","os.environ[\"HDFS_DATANODE_USER\"] = \"hduser\"\n","os.environ[\"HDFS_SECONDARYNAMENODE_USER\"] = \"hduser\"\n","\n","# Configurar archivos XML de Hadoop\n","core_site_conf = \"\"\"\n","<configuration>\n","  <property>\n","      <name>fs.defaultFS</name>\n","      <value>hdfs://localhost:9000</value>\n","  </property>\n","</configuration>\n","\"\"\"\n","\n","hdfs_site_conf = \"\"\"\n","<configuration>\n","  <property>\n","      <name>dfs.replication</name>\n","      <value>1</value>\n","  </property>\n","</configuration>\n","\"\"\"\n","\n","with open(\"/content/hadoop-3.3.6/etc/hadoop/core-site.xml\", \"w\") as f:\n","    f.write(core_site_conf)\n","\n","with open(\"/content/hadoop-3.3.6/etc/hadoop/hdfs-site.xml\", \"w\") as f:\n","    f.write(hdfs_site_conf)\n","\n","# Cambiar la propiedad y permisos del directorio Hadoop\n","!chown -R hduser:hadoop /content/hadoop-3.3.6\n","!chmod -R 755 /content/hadoop-3.3.6\n","\n","# Crear el directorio de logs\n","!mkdir -p /content/hadoop-3.3.6/logs\n","!chown -R hduser:hadoop /content/hadoop-3.3.6/logs\n","\n","# Configurar el archivo de entorno de Hadoop\n","hadoop_env_conf = \"\"\"\n","export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n","export HADOOP_HOME=/content/hadoop-3.3.6\n","export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop\n","export PATH=${HADOOP_HOME}/bin:${PATH}\n","\"\"\"\n","\n","with open(\"/content/hadoop-3.3.6/etc/hadoop/hadoop-env.sh\", \"w\") as f:\n","    f.write(hadoop_env_conf)\n","\n","# Formatear el sistema de archivos HDFS\n","!su - hduser -c \"/content/hadoop-3.3.6/bin/hdfs namenode -format\"\n","\n","# Iniciar el namenode de HDFS\n","!su - hduser -c \"/content/hadoop-3.3.6/sbin/start-dfs.sh\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zl4vrJceuhZS","executionInfo":{"status":"ok","timestamp":1743886482431,"user_tz":-120,"elapsed":353,"user":{"displayName":"RICARDO ALONZO FERNANDEZ SALGUERO","userId":"12473278373138358385"}},"outputId":"5455497a-584c-4a29-905b-a6cba750c533"},"outputs":[{"output_type":"stream","name":"stdout","text":["namenode is running as process 1674.  Stop it first and ensure /tmp/hadoop-hduser-namenode.pid file is empty before retry.\n","namenode is running as process 1674.  Stop it first and ensure /tmp/hadoop-hduser-namenode.pid file is empty before retry.\n","datanode is running as process 1746.  Stop it first and ensure /tmp/hadoop-hduser-datanode.pid file is empty before retry.\n"]}],"source":["# Formatear el sistema de archivos HDFS\n","!su - hduser -c \"export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 && /content/hadoop-3.3.6/bin/hdfs namenode -format\"\n","\n","# Iniciar el NameNode y DataNode manualmente\n","!su - hduser -c \"export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 && /content/hadoop-3.3.6/bin/hdfs --daemon start namenode\"\n","!su - hduser -c \"export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 && /content/hadoop-3.3.6/bin/hdfs --daemon start datanode\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZBB4LDMpocy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743886501177,"user_tz":-120,"elapsed":623,"user":{"displayName":"RICARDO ALONZO FERNANDEZ SALGUERO","userId":"12473278373138358385"}},"outputId":"e03cd02a-3263-4c8f-aee5-c2b2fa62ce3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["1746 DataNode\n","16710 Jps\n","1674 NameNode\n"]}],"source":["!su - hduser -c \"jps\""]},{"cell_type":"markdown","metadata":{"id":"5SabVo9qqBCx"},"source":["Estos procesos indican que:\n","\n","- `NameNode`: Es el servidor maestro de HDFS que administra el sistema de archivos y facilita las operaciones a los clientes.\n","- `DataNode`: Almacena los datos en el sistema Hadoop HDFS. Un sistema Hadoop típicamente tiene más de un DataNode, pero en este entorno de Colab, solo tenemos uno para simplificar.\n","- `Jps`: Es una herramienta que muestra todos los procesos de Java en ejecución en la máquina.\n","\n","Con el `NameNode` y `DataNode` ejecutándose correctamente, HDFS está funcionando como se esperaba en tu instancia de Colab. Ahora puedes proceder con operaciones en HDFS o realizar tareas adicionales relacionadas con Hadoop que desees explorar."]}],"metadata":{"colab":{"provenance":[{"file_id":"1qfOhkWNc1GLYjZ6csxp3NTy6GKz_FRxD","timestamp":1744656832140}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}